{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys, os\nimport pandas as pd\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.losses import categorical_crossentropy\nfrom keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom keras.regularizers import l2\nimport matplotlib.pyplot as plt\n\n#loading previously saved features and labels\na = np.load('./features.npy')\nB = np.load('./labels.npy')\n#taking the mean of the pixel features\na -= np.mean(A, axis = 0)\n#taking the normal standard deviation of the mean of the pixel features\na /= np.std(A, axis = 0)\n\n#Sklearn's test train split function using pseudo random numbers so that everytime the code is run, the output of the split is the same. 80/20 split train/test\nA_train, A_test, B_train, B_test = train_test_split(a, B, test_size = 0.1, random_state = 5)\n#making a seperate split within the train split, to give a validation set\nA_train, A_valid, B_train, B_valid = train_test_split(A_train, B_train, test_size = 0.1, random_state = 5)\n\n#saving test split using a numpy array to be used later\nnp.save('ftestFear', A_test)\nnp.save('ltestFear', B_test)\n\n#cnn model design\nmodel = Sequential()\n\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', input_shape = (48, 48, 1), data_format = 'channels_last', kernel_regularizer = l2(0.01)))\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(256, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(512, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(2, activation = 'softmax'))\n\nmodel.summary()\n\n#Compliling the model with adam optimizer and categorical crossentropy loss\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = 'Adam',\n              metrics = ['accuracy'])\n\nmodel_info = model.fit(np.array(A_train), np.array(B_train),\n          batch_size = 64,\n          epochs = 100,\n          verbose = 1,\n          validation_data = (np.array(A_valid), np.array(B_valid)),\n          callbacks = [EarlyStopping(monitor = 'val_loss', patience = int(5))],\n          shuffle = True)\n#saving the  model to be used later for testing\nCNN_json = model.to_json()\nwith open(\"CNNFear.json\", \"w\") as json_file:\n    json_file.write(CNN_json)\n    model.save_weights(\"CNNFear.h5\")\n    \n #plotting results of the training\nplt.plot(model_info.history['loss'])\nplt.plot(model_info.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc = 'upper left') \nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}